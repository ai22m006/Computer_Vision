{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import lib\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define samples count\n",
    "subset_samples = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'C:\\Users\\npaul\\fiftyone\\open-images-v7\\validation' if necessary\n",
      "Downloading 'https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv' to 'C:\\Users\\npaul\\fiftyone\\open-images-v7\\validation\\metadata\\image_ids.csv'\n",
      "Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to 'C:\\Users\\npaul\\fiftyone\\open-images-v7\\validation\\metadata\\classes.csv'\n",
      "Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to 'C:\\Users\\npaul\\AppData\\Local\\Temp\\tmp3h10rw3w\\metadata\\hierarchy.json'\n",
      "Downloading 'https://storage.googleapis.com/openimages/v5/validation-annotations-human-imagelabels-boxable.csv' to 'C:\\Users\\npaul\\fiftyone\\open-images-v7\\validation\\labels\\classifications.csv'\n",
      "Downloading 250 images\n",
      " 100% |███████████████████| 250/250 [13.0s elapsed, 0s remaining, 23.0 files/s]      \n",
      "Dataset info written to 'C:\\Users\\npaul\\fiftyone\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'person_subset'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      "Downloading split 'validation' to 'C:\\Users\\npaul\\fiftyone\\open-images-v7\\validation' if necessary\n",
      "Found 2 images, downloading the remaining 248\n",
      " 100% |███████████████████| 248/248 [12.0s elapsed, 0s remaining, 23.3 files/s]      \n",
      "Dataset info written to 'C:\\Users\\npaul\\fiftyone\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'cat_subset'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      "Downloading split 'validation' to 'C:\\Users\\npaul\\fiftyone\\open-images-v7\\validation' if necessary\n",
      "Found 5 images, downloading the remaining 245\n",
      " 100% |███████████████████| 245/245 [12.0s elapsed, 0s remaining, 21.2 files/s]      \n",
      "Dataset info written to 'C:\\Users\\npaul\\fiftyone\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'dog_subset'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "# Load a split of a zoo dataset\n",
    "person_subset = foz.load_zoo_dataset(\n",
    "    \"open-images-v7\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"classifications\"],\n",
    "    classes=[\"Person\"],\n",
    "    max_samples=subset_samples,\n",
    "    seed=51,\n",
    "    shuffle=True,\n",
    "    dataset_name=\"person_subset\",\n",
    ")\n",
    "\n",
    "cat_subset = foz.load_zoo_dataset(\n",
    "    \"open-images-v7\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"classifications\"],\n",
    "    classes=[\"Cat\"],\n",
    "    max_samples=subset_samples,\n",
    "    seed=51,\n",
    "    shuffle=True,\n",
    "    dataset_name=\"cat_subset\",\n",
    ")\n",
    "\n",
    "dog_subset = foz.load_zoo_dataset(\n",
    "    \"open-images-v7\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"classifications\"],\n",
    "    classes=[\"Dog\"],\n",
    "    max_samples=subset_samples,\n",
    "    seed=51,\n",
    "    shuffle=True,\n",
    "    dataset_name=\"dog_subset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat_dog_person_dataset', 'cat_subset', 'dog_subset', 'open-images-v7-train-500', 'open-images-v7-validation-25', 'open-images-v7-validation-500', 'person_subset']\n"
     ]
    }
   ],
   "source": [
    "# print out list of available datasets\n",
    "print(fo.list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:     person_subset\n",
      "Media type:  image\n",
      "Num samples: 742\n",
      "Sample fields:\n",
      "    id:              fiftyone.core.fields.ObjectIdField\n",
      "    filepath:        fiftyone.core.fields.StringField\n",
      "    tags:            fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:        fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    positive_labels: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classifications)\n",
      "    negative_labels: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classifications)\n",
      "    detections:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "View stages:\n",
      "    ---\n",
      "{\n",
      "    'samples_count': 742,\n",
      "    'samples_bytes': 2190038,\n",
      "    'samples_size': '2.1MB',\n",
      "    'media_bytes': 235336086,\n",
      "    'media_size': '224.4MB',\n",
      "    'total_bytes': 237526124,\n",
      "    'total_size': '226.5MB',\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "_dataset = fo.load_dataset(\"person_subset\")\n",
    "dog_subset = fo.load_dataset(\"dog_subset\")\n",
    "cat_subset = fo.load_dataset(\"cat_subset\")\n",
    "# Merge the samples together into the same dataset\n",
    "_dataset.merge_samples(dog_subset)\n",
    "_dataset.merge_samples(cat_subset)\n",
    "print(_dataset.view())\n",
    "fo.pprint(_dataset.stats(include_media=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle the order of the samples in the dataset\n",
    "_dataset = _dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 519\n",
      "Number of testing samples: 223\n"
     ]
    }
   ],
   "source": [
    "sample_ids = _dataset.values(\"id\")\n",
    "# Split the sample IDs\n",
    "train_ids, val_ids = train_test_split(sample_ids, test_size=0.3, random_state=42)\n",
    "# Get the corresponding samples for training and testing\n",
    "train_dataset = _dataset.select(train_ids)\n",
    "val_dataset = _dataset.select(val_ids)\n",
    "# Print the number of samples in each split\n",
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "print(\"Number of testing samples:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset:     person_subset\n",
       "Media type:  image\n",
       "Num samples: 519\n",
       "Sample fields:\n",
       "    id:              fiftyone.core.fields.ObjectIdField\n",
       "    filepath:        fiftyone.core.fields.StringField\n",
       "    tags:            fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
       "    metadata:        fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
       "    positive_labels: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classifications)\n",
       "    negative_labels: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classifications)\n",
       "    detections:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
       "View stages:\n",
       "    1. Shuffle(seed=None)\n",
       "    2. Select(sample_ids=['6479cb4cfa920d5506fd3c68', '6479cb4cfa920d5506fd400e', '6479cb4cfa920d5506fd3c6c', ...], ordered=False)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parametes\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_scratch = Sequential()\n",
    "model_scratch.add(VGG19(include_top=False, weights=None, input_shape=(224, 224, 3)))  # VGG19 without the top layer\n",
    "model_scratch.add(Flatten())\n",
    "model_scratch.add(Dense(256, activation='relu'))\n",
    "model_scratch.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[177], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m model_scratch\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mAdam(), loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m model_scratch\u001B[38;5;241m.\u001B[39mfit(\u001B[43mX_train\u001B[49m, y_train, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, validation_data\u001B[38;5;241m=\u001B[39m(X_test, y_test))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_scratch.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model_scratch.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
