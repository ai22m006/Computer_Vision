{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Project 6\n",
    "Choose three classes from the Open Images Dataset. Train a neural net that is able to classify images into these three categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T15:15:46.258963700Z",
     "start_time": "2023-06-02T15:15:46.253592500Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = ['Cat', 'Dog', 'Person']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "https://storage.googleapis.com/openimages/web/visualizer/index.html?type=detection\n",
    "\n",
    "## Base model\n",
    "VGG 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T15:15:48.006758600Z",
     "start_time": "2023-06-02T15:15:46.257964100Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.applications import VGG19\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from openimages import download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T15:21:53.175734800Z",
     "start_time": "2023-06-02T15:15:48.005759100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02  17:17:38 INFO Downloading 2000 train images for class 'cat'\n",
      "100%|██████████| 2000/2000 [01:18<00:00, 25.44it/s]\n",
      "2023-06-02  17:18:57 INFO Downloading 2000 train images for class 'dog'\n",
      "100%|█████████▉| 1994/2000 [01:22<00:00, 30.17it/s]2023-06-02  17:20:20 WARNING Connection pool is full, discarding connection: open-images-dataset.s3.amazonaws.com. Connection pool size: 10\n",
      "100%|██████████| 2000/2000 [01:23<00:00, 24.07it/s]\n",
      "2023-06-02  17:20:21 INFO Downloading 2000 train images for class 'person'\n",
      "100%|██████████| 2000/2000 [01:22<00:00, 24.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cat': {'images_dir': './dataset\\\\cat\\\\images'},\n",
       " 'dog': {'images_dir': './dataset\\\\dog\\\\images'},\n",
       " 'person': {'images_dir': './dataset\\\\person\\\\images'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the directory where the images are stored\n",
    "base_dir = './dataset'\n",
    "n_images = 2000  # number of images per class\n",
    "\n",
    "# Download images for each class using Open Images\n",
    "download.download_dataset(\n",
    "    class_labels=classes,\n",
    "    dest_dir=base_dir,\n",
    "    limit=n_images\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "1. Preparation: Split dataset into a 70/30 Train/test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T15:21:53.256307900Z",
     "start_time": "2023-06-02T15:21:53.174734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4200 images belonging to 3 classes.\n",
      "Found 1800 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define parameters for the loader\n",
    "batch_size = 20\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Load the training data\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.3)  # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')  # set as training data\n",
    "\n",
    "# Load the validation data\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')  # set as validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train a VGG19 network from scratch (randomly initialized weights) and estimate the testset accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T15:21:53.931930200Z",
     "start_time": "2023-06-02T15:21:53.254133200Z"
    }
   },
   "outputs": [],
   "source": [
    "# load a vgg19 with random init weights\n",
    "random_base_vgg19 = VGG19(weights=None, include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# TODO estimate testset accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Transfer learning: Use an imagenet pretrained VGG19 network, train the model and estimate the testset accuracy. Show the differences in loss and accuracy of the plain and pre trained network over the first 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T15:41:16.881751300Z",
     "start_time": "2023-06-02T15:21:53.933431300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "210/210 [==============================] - 228s 1s/step - loss: 1.7852 - accuracy: 0.5886 - val_loss: 0.7750 - val_accuracy: 0.6617\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 230s 1s/step - loss: 0.6875 - accuracy: 0.7005 - val_loss: 0.7644 - val_accuracy: 0.6650\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 233s 1s/step - loss: 0.6082 - accuracy: 0.7412 - val_loss: 0.9172 - val_accuracy: 0.6228\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 236s 1s/step - loss: 0.5999 - accuracy: 0.7417 - val_loss: 0.7081 - val_accuracy: 0.6944\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 236s 1s/step - loss: 0.5270 - accuracy: 0.7812 - val_loss: 0.6890 - val_accuracy: 0.6972\n"
     ]
    }
   ],
   "source": [
    "# Load the VGG19 model\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model on top of the base model\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(classes), activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=10)\n",
    "\n",
    "# Save the model\n",
    "model.save('models/model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Data cleansing: Remove “bad” images from the dataset. Which did you remove? How many? Discuss results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T15:41:16.883548700Z",
     "start_time": "2023-06-02T15:41:16.882041300Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Add data augmentation and train again, discuss results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T15:41:16.885523Z",
     "start_time": "2023-06-02T15:41:16.883548700Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Rebuild VGG19. After layer block4_conv4 (25, 25, 512):\n",
    "    - Random flip\n",
    "    - Random contrast\n",
    "    - Random translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T15:41:16.887649200Z",
     "start_time": "2023-06-02T15:41:16.885523Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Test a few of your own images and present the results\n",
    "    - Add inception layer with dimensionality reduction (no of output filters should be 512, choose own values for the filter dimensionality reduction in 1x1 layers)\n",
    "    - Add conv layer (kernel 1x1,  filters 1024, padding valid, stride 1, activation leaky relu)\n",
    "    - Add conv layer (kernel 3x3,  filters 1024, padding same, stride 1, activation relu)\n",
    "    - Freeze conv2 layers and before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T15:41:16.889883100Z",
     "start_time": "2023-06-02T15:41:16.888376100Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Answer the following questions:\n",
    "    - What accuracy can be achieved? What is the accuracy of the train vs. test set?\n",
    "    - On what infrastructure did you train it? What is the inference time?\n",
    "    - What are the number of parameters of the model?\n",
    "    - Which categories are most likely to be confused by the algorithm? Show results in a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T15:41:16.891391Z",
     "start_time": "2023-06-02T15:41:16.890383200Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results of the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T15:41:16.893941300Z",
     "start_time": "2023-06-02T15:41:16.892390200Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
